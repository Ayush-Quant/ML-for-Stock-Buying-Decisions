# -*- coding: utf-8 -*-
"""ML-for-Stock-Buying-Decisions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hb-BQ7ROpbqL72wjUSJs5WKNwUGwKiUk
"""

# Importing the required libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC, SVR
from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb
from statsmodels.tsa.statespace.sarimax import SARIMAX

# Loading the dataset

data = pd.read_csv("nse_3_year_stock_data - Copy.csv")

# Inspecting the dataset

print(data.head())
print(data.info())

data

file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)

df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")

RELIANCE_df    = df[["Date", "RELIANCE.NS"]].rename(columns={"RELIANCE.NS": "Price"})
HDFCBANK_df    = df[["Date", "HDFCBANK.NS"]].rename(columns={"HDFCBANK.NS": "Price"})
LT_df          = df[["Date", "LT.NS"]].rename(columns={"LT.NS": "Price"})
MM_df          = df[["Date", "M&M.NS"]].rename(columns={"M&M.NS": "Price"})
ITC_df         = df[["Date", "ITC.NS"]].rename(columns={"ITC.NS": "Price"})
ONGC_df        = df[["Date", "ONGC.NS"]].rename(columns={"ONGC.NS": "Price"})
ASIANPAINT_df  = df[["Date", "ASIANPAINT.NS"]].rename(columns={"ASIANPAINT.NS": "Price"})
HINDUNILVR_df  = df[["Date", "HINDUNILVR.NS"]].rename(columns={"HINDUNILVR.NS": "Price"})
CIPLA_df       = df[["Date", "CIPLA.NS"]].rename(columns={"CIPLA.NS": "Price"})
TRENT_df       = df[["Date", "TRENT.NS"]].rename(columns={"TRENT.NS": "Price"})

# Example check
print(HDFCBANK_df.head())
print(ITC_df.head())

"""Predicting the stock buying behavior of each stock using the Support Vector Classifier."""

# Load data
file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

# Function to run SVC strategy on one stock
def run_svc_strategy(prices, stock_name):
    # Calculate daily returns
    returns = prices.pct_change().dropna()

    # Features: lagged returns
    X = pd.DataFrame({
        "lag1": returns.shift(1),
        "lag2": returns.shift(2)
    }).dropna()

    # Target: 1 if return > 0, else 0
    y = (returns.loc[X.index] > 0).astype(int)

    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, shuffle=False
    )

    # Scale features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Train SVC
    model = SVC(kernel="rbf", C=1.0, gamma="scale")
    model.fit(X_train_scaled, y_train)

    # Predict signals
    signals = pd.Series(model.predict(np.vstack([X_train_scaled, X_test_scaled])),
                        index=X.index)

    # Strategy returns = signals * actual returns
    strategy_returns = signals * returns.loc[X.index]

    # Cumulative returns
    cum_actual = (1 + returns.loc[X.index]).cumprod()
    cum_strategy = (1 + strategy_returns).cumprod()

    # Plot comparison
    plt.figure(figsize=(10,5))
    plt.plot(cum_actual, label="Actual Cumulative Returns")
    plt.plot(cum_strategy, label="SVC Strategy Cumulative Returns")
    plt.title(f"{stock_name} - Actual vs SVC Strategy Returns")
    plt.legend()
    plt.show()

    return cum_actual, cum_strategy

# Run for all stocks
results = {}
for stock in df.columns:
    cum_actual, cum_strategy = run_svc_strategy(df[stock], stock)
    results[stock] = {"Actual": cum_actual, "SVC": cum_strategy}

"""Creating a portfolio of the selected 10 stocks with equal weightage and checking the cumulative return of the portfolio from SVC prediction with the actual cumulative return of Nifty50 index."""

# Load stock data
file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

nifty_df = df[["RELIANCE.NS"]].rename(columns={"RELIANCE.NS": "NIFTY50"})

def svc_strategy(prices):
    returns = prices.pct_change().dropna()


    X = pd.DataFrame({
        "lag1": returns.shift(1),
        "lag2": returns.shift(2)
    }).dropna()

    # Target: 1 if return > 0, else 0
    y = (returns.loc[X.index] > 0).astype(int)


    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, shuffle=False
    )

    # Scale
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = SVC(kernel="rbf", C=1.0, gamma="scale")
    model.fit(X_train_scaled, y_train)

    # Predict signals (1=Buy, 0=No position)
    signals = pd.Series(model.predict(np.vstack([X_train_scaled, X_test_scaled])),
                        index=X.index)

    # Strategy return = signal * actual return
    strategy_returns = signals * returns.loc[X.index]

    return strategy_returns

strategy_returns_all = pd.DataFrame()

for stock in df.columns:
    strategy_returns_all[stock] = svc_strategy(df[stock])

portfolio_strategy_returns = strategy_returns_all.mean(axis=1)


actual_returns_all = df.pct_change().dropna()
portfolio_actual_returns = actual_returns_all.mean(axis=1)

benchmark_returns = nifty_df.pct_change().dropna()["NIFTY50"]

common_index = portfolio_strategy_returns.index.intersection(benchmark_returns.index)
portfolio_strategy_returns = portfolio_strategy_returns.loc[common_index]
portfolio_actual_returns = portfolio_actual_returns.loc[common_index]
benchmark_returns = benchmark_returns.loc[common_index]

cum_strategy = (1 + portfolio_strategy_returns).cumprod()
cum_actual_portfolio = (1 + portfolio_actual_returns).cumprod()
cum_benchmark = (1 + benchmark_returns).cumprod()

plt.figure(figsize=(12,6))
plt.plot(cum_strategy, label="SVC Strategy Portfolio")
plt.plot(cum_actual_portfolio, label="Actual Equal-Weighted Portfolio")
plt.plot(cum_benchmark, label="Nifty50")
plt.title("Portfolio Cumulative Returns vs Benchmark")
plt.legend()
plt.show()

"""PART 2:
Using SARIMAX to predict the stock prices of each stock.
"""

# Load stock data
file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

# Parameters for SARIMAX
order = (1, 1, 1)
seasonal_order = (1, 1, 1, 5)  # weekly seasonality (5 trading days)

# Function to fit SARIMAX and forecast
def sarimax_forecast(prices, steps=30):
    model = SARIMAX(prices, order=order, seasonal_order=seasonal_order,
                    enforce_stationarity=False, enforce_invertibility=False)
    results = model.fit(disp=False)

    forecast = results.get_forecast(steps=steps)

    # Create proper forecast index
    forecast_index = pd.date_range(start=prices.index[-1] + pd.Timedelta(days=1),
                                   periods=steps, freq="B")  # business days
    forecast_mean = pd.Series(forecast.predicted_mean.values, index=forecast_index)
    forecast_ci = forecast.conf_int()
    forecast_ci.index = forecast_index

    return forecast_mean, forecast_ci

# Run SARIMAX for each stock and plot
for stock in df.columns:
    prices = df[stock].dropna()
    forecast_mean, forecast_ci = sarimax_forecast(prices, steps=30)

    plt.figure(figsize=(10,5))
    plt.plot(prices[-100:], label="Actual")  # show last 100 points
    plt.plot(forecast_mean.index, forecast_mean, label="Forecast", linestyle="--", color="orange")
    plt.fill_between(forecast_ci.index,
                     forecast_ci.iloc[:, 0],
                     forecast_ci.iloc[:, 1],
                     color="orange", alpha=0.2)
    plt.title(f"SARIMAX Forecast - {stock}")
    plt.legend()
    plt.show()

"""Predicting the stock price using support vector regression (SVR)"""

file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

# List of stocks in your dataset (column names)
stocks = df.columns.tolist()

def svr_stock_prediction(stock_data, stock_name):
    X = np.arange(len(stock_data)).reshape(-1, 1)  # Dates as numerical values
    y = stock_data.values.reshape(-1, 1)

    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    X_scaled = scaler_X.fit_transform(X)
    y_scaled = scaler_y.fit_transform(y)

    svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)
    svr_rbf.fit(X_scaled, y_scaled.ravel())

    y_pred_scaled = svr_rbf.predict(X_scaled)
    y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))

    plt.figure(figsize=(10, 5))
    plt.plot(stock_data.index, stock_data.values, color='blue', label='Actual Price')
    plt.plot(stock_data.index, y_pred, color='red', label='SVR Predicted Price')
    plt.title(f"{stock_name} Stock Price Prediction using SVR")
    plt.xlabel("Date")
    plt.ylabel("Price")
    plt.legend()
    plt.show()

for stock in stocks:
    print(f"Predicting for {stock}...")
    svr_stock_prediction(df[stock], stock)

"""Predicting the stock prices using XGBoost"""

file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

stocks = df.columns.tolist()

# Function to create lag features
def create_lag_features(data, lag=5):
    X, y = [], []
    for i in range(lag, len(data)):
        X.append(data[i-lag:i])
        y.append(data[i])
    return np.array(X), np.array(y)

# Function to predict stock prices using XGBoost
def xgb_stock_prediction(stock_data, stock_name, lag=5):
    prices = stock_data.values
    X, y = create_lag_features(prices, lag=lag)

    # Train-test split
    split = int(0.8 * len(X))
    X_train, X_test = X[:split], X[split:]
    y_train, y_test = y[:split], y[split:]

    # Train XGBoost model
    model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05)
    model.fit(X_train, y_train)

    # Predictions
    y_pred = model.predict(X_test)

    # Plot actual vs predicted
    plt.figure(figsize=(10, 5))
    plt.plot(stock_data.index[lag+split:], y_test, color='blue', label='Actual Price')
    plt.plot(stock_data.index[lag+split:], y_pred, color='red', label='XGBoost Predicted Price')
    plt.title(f"{stock_name} Stock Price Prediction using XGBoost")
    plt.xlabel("Date")
    plt.ylabel("Price")
    plt.legend()
    plt.show()

    # Print RMSE
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    print(f"{stock_name} RMSE: {rmse:.2f}")

# Loop through each stock
for stock in stocks:
    print(f"Predicting for {stock}...")
    xgb_stock_prediction(df[stock], stock)

"""Plotting the stock price versus the predicted stock price with those from SARIMAX and SVR and XGBoost."""

file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)

stocks = df.columns.tolist()

# Function to create lag features for XGBoost
def create_lag_features(data, lag=5):
    X, y = [], []
    for i in range(lag, len(data)):
        X.append(data[i-lag:i])
        y.append(data[i])
    return np.array(X), np.array(y)

# Dictionary to store results
results = {"Stock": [], "Model": [], "MSE": [], "RMSE": [], "R2": []}

for stock in stocks:
    print(f"Processing {stock}...")

    prices = df[stock].values
    dates = df.index

    # SARIMAX
    try:
        # Split data 80-20
        split = int(0.8 * len(prices))
        train, test = prices[:split], prices[split:]

        # Fit SARIMAX (simple non-seasonal ARIMA for demonstration)
        sarimax_model = SARIMAX(train, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)
        sarimax_fit = sarimax_model.fit(disp=False)

        sarimax_pred = sarimax_fit.forecast(steps=len(test))

        results["Stock"].append(stock)
        results["Model"].append("SARIMAX")
        results["MSE"].append(mean_squared_error(test, sarimax_pred))
        results["RMSE"].append(np.sqrt(mean_squared_error(test, sarimax_pred)))
        results["R2"].append(r2_score(test, sarimax_pred))
    except:
        print(f"SARIMAX failed for {stock}")
        results["Stock"].append(stock)
        results["Model"].append("SARIMAX")
        results["MSE"].append(np.nan)
        results["RMSE"].append(np.nan)
        results["R2"].append(np.nan)

    # SVR
    try:
        X_svr = np.arange(len(prices)).reshape(-1,1)
        y_svr = prices.reshape(-1,1)

        scaler_X = StandardScaler()
        scaler_y = StandardScaler()

        X_scaled = scaler_X.fit_transform(X_svr)
        y_scaled = scaler_y.fit_transform(y_svr)

        split = int(0.8 * len(X_scaled))
        X_train, X_test = X_scaled[:split], X_scaled[split:]
        y_train, y_test = y_scaled[:split], y_scaled[split:]

        svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)
        svr_model.fit(X_train, y_train.ravel())

        y_pred_scaled = svr_model.predict(X_test)
        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1,1))

        results["Stock"].append(stock)
        results["Model"].append("SVR")
        results["MSE"].append(mean_squared_error(prices[split:], y_pred))
        results["RMSE"].append(np.sqrt(mean_squared_error(prices[split:], y_pred)))
        results["R2"].append(r2_score(prices[split:], y_pred))
    except:
        print(f"SVR failed for {stock}")
        results["Stock"].append(stock)
        results["Model"].append("SVR")
        results["MSE"].append(np.nan)
        results["RMSE"].append(np.nan)
        results["R2"].append(np.nan)

    # XGBoost
    try:
        lag = 5
        X_xgb, y_xgb = create_lag_features(prices, lag=lag)
        split = int(0.8 * len(X_xgb))
        X_train, X_test = X_xgb[:split], X_xgb[split:]
        y_train, y_test = y_xgb[:split], y_xgb[split:]

        xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05)
        xgb_model.fit(X_train, y_train)

        y_pred = xgb_model.predict(X_test)

        results["Stock"].append(stock)
        results["Model"].append("XGBoost")
        results["MSE"].append(mean_squared_error(y_test, y_pred))
        results["RMSE"].append(np.sqrt(mean_squared_error(y_test, y_pred)))
        results["R2"].append(r2_score(y_test, y_pred))
    except:
        print(f"XGBoost failed for {stock}")
        results["Stock"].append(stock)
        results["Model"].append("XGBoost")
        results["MSE"].append(np.nan)
        results["RMSE"].append(np.nan)
        results["R2"].append(np.nan)


results_df = pd.DataFrame(results)
print("\nModel Comparison Table:")
print(results_df)

"""From the diagnostics ran from the above exercise we can clearly see that XGBoost proves to be the better tool over SARIMAX and SVR to predict the stock prices. Only for HDFC Bank XGBoost gives a negative R-square value, although for HDFC Bank SVR gives a positive R-Square it is still very low."""

!pip install CatBoost

"""Using Catboost we have compared the previous results with 2 stocks i.e. Reliance and Mahindra & Mahindra."""

stock = "RELIANCE.NS"
prices = df[stock].values
dates = df.index

# CatBoost
def create_lag_features(data, lag=5):
    X, y = [], []
    for i in range(lag, len(data)):
        X.append(data[i-lag:i])
        y.append(data[i])
    return np.array(X), np.array(y)

lag = 5
X_cb, y_cb = create_lag_features(prices, lag=lag)
split = int(0.8 * len(X_cb))
X_train_cb, X_test_cb = X_cb[:split], X_cb[split:]
y_train_cb, y_test_cb = y_cb[:split], y_cb[split:]

cat_model = CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=6, verbose=0)
cat_model.fit(X_train_cb, y_train_cb)
y_pred_cb = cat_model.predict(X_test_cb)

mse_cb = mean_squared_error(y_test_cb, y_pred_cb)
rmse_cb = np.sqrt(mse_cb)
r2_cb = r2_score(y_test_cb, y_pred_cb)

# SARIMAX
split_index = int(0.8*len(prices))
train, test = prices[:split_index], prices[split_index:]
sarimax_model = SARIMAX(train, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)
sarimax_fit = sarimax_model.fit(disp=False)
sarimax_pred = sarimax_fit.forecast(steps=len(test))
mse_sarimax = mean_squared_error(test, sarimax_pred)
rmse_sarimax = np.sqrt(mse_sarimax)
r2_sarimax = r2_score(test, sarimax_pred)

# SVR
X_svr = np.arange(len(prices)).reshape(-1,1)
y_svr = prices.reshape(-1,1)
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X_svr)
y_scaled = scaler_y.fit_transform(y_svr)
X_train_svr, X_test_svr = X_scaled[:split_index], X_scaled[split_index:]
y_train_svr, y_test_svr = y_scaled[:split_index], y_scaled[split_index:]
svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)
svr_model.fit(X_train_svr, y_train_svr.ravel())
y_pred_scaled_svr = svr_model.predict(X_test_svr)
y_pred_svr = scaler_y.inverse_transform(y_pred_scaled_svr.reshape(-1,1))
mse_svr = mean_squared_error(prices[split_index:], y_pred_svr)
rmse_svr = np.sqrt(mse_svr)
r2_svr = r2_score(prices[split_index:], y_pred_svr)

# XGBoost
X_xgb, y_xgb = create_lag_features(prices, lag=5)
split_xgb = int(0.8*len(X_xgb))
X_train_xgb, X_test_xgb = X_xgb[:split_xgb], X_xgb[split_xgb:]
y_train_xgb, y_test_xgb = y_xgb[:split_xgb], y_xgb[split_xgb:]
xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05)
xgb_model.fit(X_train_xgb, y_train_xgb)
y_pred_xgb = xgb_model.predict(X_test_xgb)
mse_xgb = mean_squared_error(y_test_xgb, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test_xgb, y_pred_xgb)

# Comparison Table
comparison = pd.DataFrame({
    "Model": ["CatBoost", "SARIMAX", "SVR", "XGBoost"],
    "MSE": [mse_cb, mse_sarimax, mse_svr, mse_xgb],
    "RMSE": [rmse_cb, rmse_sarimax, rmse_svr, rmse_xgb],
    "R2": [r2_cb, r2_sarimax, r2_svr, r2_xgb]
})

print("\nPerformance Comparison for RELIANCE.NS:")
print(comparison)

file_path = "nse_3_year_stock_data - Copy.csv"
df = pd.read_csv(file_path)
df["Date"] = pd.to_datetime(df["Date"], format="%d-%m-%Y")
df.set_index("Date", inplace=True)
stock = "M&M.NS"
prices = df[stock].values
dates = df.index

def create_lag_features(data, lag=5):
    X, y = [], []
    for i in range(lag, len(data)):
        X.append(data[i-lag:i])
        y.append(data[i])
    return np.array(X), np.array(y)

lag = 5
X_cb, y_cb = create_lag_features(prices, lag=lag)
split = int(0.8 * len(X_cb))
X_train_cb, X_test_cb = X_cb[:split], X_cb[split:]
y_train_cb, y_test_cb = y_cb[:split], y_cb[split:]

cat_model = CatBoostRegressor(iterations=1000, learning_rate=0.05, depth=6, verbose=0)
cat_model.fit(X_train_cb, y_train_cb)
y_pred_cb = cat_model.predict(X_test_cb)

mse_cb = mean_squared_error(y_test_cb, y_pred_cb)
rmse_cb = np.sqrt(mse_cb)
r2_cb = r2_score(y_test_cb, y_pred_cb)

split_index = int(0.8*len(prices))
train, test = prices[:split_index], prices[split_index:]
sarimax_model = SARIMAX(train, order=(1,1,1), enforce_stationarity=False, enforce_invertibility=False)
sarimax_fit = sarimax_model.fit(disp=False)
sarimax_pred = sarimax_fit.forecast(steps=len(test))
mse_sarimax = mean_squared_error(test, sarimax_pred)
rmse_sarimax = np.sqrt(mse_sarimax)
r2_sarimax = r2_score(test, sarimax_pred)

X_svr = np.arange(len(prices)).reshape(-1,1)
y_svr = prices.reshape(-1,1)
scaler_X = StandardScaler()
scaler_y = StandardScaler()
X_scaled = scaler_X.fit_transform(X_svr)
y_scaled = scaler_y.fit_transform(y_svr)
X_train_svr, X_test_svr = X_scaled[:split_index], X_scaled[split_index:]
y_train_svr, y_test_svr = y_scaled[:split_index], y_scaled[split_index:]
svr_model = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.01)
svr_model.fit(X_train_svr, y_train_svr.ravel())
y_pred_scaled_svr = svr_model.predict(X_test_svr)
y_pred_svr = scaler_y.inverse_transform(y_pred_scaled_svr.reshape(-1,1))
mse_svr = mean_squared_error(prices[split_index:], y_pred_svr)
rmse_svr = np.sqrt(mse_svr)
r2_svr = r2_score(prices[split_index:], y_pred_svr)

X_xgb, y_xgb = create_lag_features(prices, lag=5)
split_xgb = int(0.8*len(X_xgb))
X_train_xgb, X_test_xgb = X_xgb[:split_xgb], X_xgb[split_xgb:]
y_train_xgb, y_test_xgb = y_xgb[:split_xgb], y_xgb[split_xgb:]
xgb_model = XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05)
xgb_model.fit(X_train_xgb, y_train_xgb)
y_pred_xgb = xgb_model.predict(X_test_xgb)
mse_xgb = mean_squared_error(y_test_xgb, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)
r2_xgb = r2_score(y_test_xgb, y_pred_xgb)

comparison = pd.DataFrame({
    "Model": ["CatBoost", "SARIMAX", "SVR", "XGBoost"],
    "MSE": [mse_cb, mse_sarimax, mse_svr, mse_xgb],
    "RMSE": [rmse_cb, rmse_sarimax, rmse_svr, rmse_xgb],
    "R2": [r2_cb, r2_sarimax, r2_svr, r2_xgb]
})

print("\nPerformance Comparison for RELIANCE.NS:")
print(comparison)

"""We have used CatBoost for stock price prediction and it does give better results than SARIMAX, SVR and XGboost for the 2 selected stocks.
The benefits of using CatBoost:
1. Handles Non-Linear Relationshhips better
2. Handles Tabular Data Effectively
3. Automatic Feature Handling
4. Faster and more stable model training.
"""